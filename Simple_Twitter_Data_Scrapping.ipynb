{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln7DDg4Z5MgW"
      },
      "source": [
        "# \"Datascraping using Twitter\"\n",
        "> \"Scrapping Tweet data using python\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/tweepy/tweepy.git\n",
        "!pip install textblob\n",
        "# !pip install pycountry\n",
        "# !pip install langdetect\n",
        "!pip install Sastrawi\n",
        "!pip install swifter\n",
        "!pip install itranslate"
      ],
      "metadata": {
        "id": "tAdXbgtFEr2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vghls9Y65Mgd"
      },
      "outputs": [],
      "source": [
        "#collapse_show\n",
        "#importing libraries\n",
        "from textblob import TextBlob\n",
        "import sys\n",
        "import tweepy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import nltk\n",
        "# import pycountry\n",
        "import re\n",
        "import string\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from PIL import Image\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "# from langdetect import detect\n",
        "from nltk.stem import SnowballStemmer\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('stopwords') \n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmOY-e075Mgf"
      },
      "source": [
        "To access the Twitter API, we will need 4 things from your Twitter page. These keys are located in your Twitter app settings in the Keys and Access Tokens tab:\n",
        "\n",
        "- consumer key\n",
        "- consumer seceret key\n",
        "- access token key\n",
        "- access token secret key\n",
        "\n",
        "[Detailed info for getting keys](https://www.slickremix.com/docs/how-to-get-api-keys-and-tokens-for-twitter/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSF8jbSr5Mgg"
      },
      "outputs": [],
      "source": [
        "#for privacy purposes, these keys are encrypted\n",
        "consumer_key=\"{consumer_key}\"\n",
        "consumer_secret=\"{consumer_secret}\"\n",
        "access_token=\"{access_token}\"\n",
        "access_token_secret=\"{access_token_secret}\"\n",
        "bearer_key=\"{bearer_key}\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use bearer token. We use this token because we use the new twitter API v2."
      ],
      "metadata": {
        "id": "ILJGT94MUtlU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQ26CQRj5Mgh"
      },
      "outputs": [],
      "source": [
        "#define client from tweepy\n",
        "\n",
        "client = tweepy.Client(bearer_token=bearer_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld8tRgO-5Mgm"
      },
      "source": [
        "One major problem the is being faced is that when we convert a list in data frame, if the tweet text is >50 chars it gets truncated. To solve this issue, we need to set display column width for pandas dataframe to be -1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzbLuLy05Mgp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da180729-43d4-43c4-a7ef-8baf7a4363c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "#collapse_show\n",
        "pd.set_option('display.max_colwidth', -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get tweet mentioning specific query, it is more like search for specific text in a tweet."
      ],
      "metadata": {
        "id": "qoXU4MVTUgGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# drive.mount('/content/drive/csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HORaNVpnF1eW",
        "outputId": "fe0915ff-8090-4ee4-dd51-aa1ba29c1ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'ppkm'\n",
        "\n",
        "# Replace the limit=1000 with the maximum number of Tweets you want\n",
        "tweets= tweepy.Paginator(client.search_recent_tweets, query=query,\n",
        "                              tweet_fields=['context_annotations', 'created_at']).flatten(limit=300)\n",
        "tweet_list= [[tweet.created_at, tweet.id, tweet.text] for tweet in tweets]\n",
        "#creating dataframe from tweets list\n",
        "tweets_df1=pd.DataFrame(tweet_list, columns=[\"Date\",\"Tweet_id\",\"Tweet_Text\"])\n",
        "\n",
        "#download twitter dataset\n",
        "# file_name = '/content/drive/MyDrive/Colab Notebooks/dataset_ppkm.csv'\n",
        "# tweets_df.to_csv(file_name, encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "C9N24bXHRwZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'ppkm level 2 OR ppkm level dua'\n",
        "\n",
        "# Replace the limit=1000 with the maximum number of Tweets you want\n",
        "tweets= tweepy.Paginator(client.search_recent_tweets, query=query,\n",
        "                              tweet_fields=['context_annotations', 'created_at']).flatten(limit=300)\n",
        "tweet_list= [[tweet.created_at, tweet.id, tweet.text] for tweet in tweets]\n",
        "#creating dataframe from tweets list\n",
        "tweets_df2=pd.DataFrame(tweet_list, columns=[\"Date\",\"Tweet_id\",\"Tweet_Text\"])\n",
        "\n",
        "#download twitter dataset\n",
        "# file_name = '/content/drive/MyDrive/Colab Notebooks/dataset_lvl2.csv'\n",
        "# tweets_df.to_csv(file_name, encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "LSlAkdPyxYrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'ppkm level 3 OR ppkm level tiga'\n",
        "\n",
        "# Replace the limit=1000 with the maximum number of Tweets you want\n",
        "tweets= tweepy.Paginator(client.search_recent_tweets, query=query,\n",
        "                              tweet_fields=['context_annotations', 'created_at']).flatten(limit=300)\n",
        "tweet_list= [[tweet.created_at, tweet.id, tweet.text] for tweet in tweets]\n",
        "#creating dataframe from tweets list\n",
        "tweets_df3=pd.DataFrame(tweet_list, columns=[\"Date\",\"Tweet_id\",\"Tweet_Text\"])\n",
        "\n",
        "#download twitter dataset\n",
        "# file_name = '/content/drive/MyDrive/Colab Notebooks/dataset_lvl3.csv'\n",
        "# tweets_df.to_csv(file_name, encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "cAo7UXUYxZS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'ppkm level 4 OR ppkm level empat'\n",
        "\n",
        "# Replace the limit=1000 with the maximum number of Tweets you want\n",
        "tweets= tweepy.Paginator(client.search_recent_tweets, query=query,\n",
        "                              tweet_fields=['context_annotations', 'created_at']).flatten(limit=300)\n",
        "tweet_list= [[tweet.created_at, tweet.id, tweet.text] for tweet in tweets]\n",
        "#creating dataframe from tweets list\n",
        "tweets_df4=pd.DataFrame(tweet_list, columns=[\"Date\",\"Tweet_id\",\"Tweet_Text\"])\n",
        "\n",
        "#combine df\n",
        "tweets_df = pd.concat([tweets_df1, tweets_df2,tweets_df3,tweets_df4])\n",
        "\n",
        "#download twitter dataset\n",
        "# file_name = '/content/drive/MyDrive/Colab Notebooks/csv/dataset_ppkm.csv'\n",
        "file_name = 'dataset_ppkm.csv'\n",
        "tweets_df.to_csv(file_name, encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "LUa7udrixZ-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_df.shape"
      ],
      "metadata": {
        "id": "iysSkI_FzY6w",
        "outputId": "5d358d1c-2b81-4367-e7d4-5689a579dcc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1100, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# case folding\n",
        "tweets_df['Tweet_Text'] = tweets_df['Tweet_Text'].str.lower()\n",
        "tweets_df.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjkzgiQimJdL",
        "outputId": "44b674ae-498e-4c50-b4da-901e3c3c0de5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                         Date  ...  Tweet_Lang\n",
              "0  2022-03-03 15:35:34+00:00  ...  None      \n",
              "1  2022-03-03 15:35:30+00:00  ...  None      \n",
              "2  2022-03-03 15:34:23+00:00  ...  None      \n",
              "3  2022-03-03 15:34:10+00:00  ...  None      \n",
              "4  2022-03-03 15:31:20+00:00  ...  None      \n",
              "..                       ...  ...   ...      \n",
              "95 2022-03-03 13:26:04+00:00  ...  None      \n",
              "96 2022-03-03 13:24:52+00:00  ...  None      \n",
              "97 2022-03-03 13:24:07+00:00  ...  None      \n",
              "98 2022-03-03 13:24:04+00:00  ...  None      \n",
              "99 2022-03-03 13:21:39+00:00  ...  None      \n",
              "\n",
              "[100 rows x 4 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaning text\n",
        "\n",
        "def remove_tweet_special(text):\n",
        "    # remove tab, new line, ans back slice\n",
        "    text = text.replace('\\\\t',\" \").replace('\\\\n',\" \").replace('\\\\u',\" \").replace('\\\\',\"\")\n",
        "    # remove non ASCII (emoticon, chinese word, .etc)\n",
        "    text = text.encode('ascii', 'replace').decode('ascii')\n",
        "    # remove mention, link, hashtag\n",
        "    text = ' '.join(replace.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", text).split())\n",
        "    # remove incomplete URL\n",
        "    return text.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
        "                \n",
        "tweets_df['Tweet_Text'] = tweets_df['Tweet_Text'].apply(remove_tweet_special)\n",
        "\n",
        "#remove number\n",
        "def remove_number(text):\n",
        "    return  re.sub(r\"\\d+\", \"\", text)\n",
        "\n",
        "tweets_df['Tweet_Text'] = tweets_df['Tweet_Text'].apply(remove_number)\n",
        "\n",
        "#remove punctuation\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
        "\n",
        "tweets_df['Tweet_Text'] = tweets_df['Tweet_Text'].apply(remove_punctuation)\n",
        "\n",
        "#remove whitespace leading & trailing\n",
        "def remove_whitespace_LT(text):\n",
        "    return text.strip()\n",
        "\n",
        "tweets_df['Tweet_Text'] = tweets_df['Tweet_Text'].apply(remove_whitespace_LT)\n",
        "\n",
        "#remove multiple whitespace into single whitespace\n",
        "def remove_whitespace_multiple(text):\n",
        "    return re.sub('\\s+',' ',text)\n",
        "\n",
        "tweets_df['Tweet_Text'] = tweets_df['Tweet_Text'].apply(remove_whitespace_multiple)\n",
        "\n",
        "# remove single char\n",
        "def remove_singl_char(text):\n",
        "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
        "\n",
        "tweets_df['Tweet_Text'] = tweets_df['Tweet_Text'].apply(remove_singl_char)\n",
        "\n",
        "tweets_df['Tweet_Text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRdOTgtYWjFA",
        "outputId": "0586fd4a-d114-4970-b758-09b6c2a6dd38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     rt                                                                                                                                             \n",
              "1     dah tutup warungnya lagi ppkm                                                                                                                  \n",
              "2     demi keselamatan masyarakat pemerintah kembali terapkan ppkm untuk menekan penyebaran covid varian omicron prokes ikhtiar bersama              \n",
              "3     rt sridianava isi chat grup para emak pusing gas bbm sembako naik pusing migor kedelai tahu tempe langka pusing anak sekolah onlin             \n",
              "4     hafalan doa dan dzikir setelah shalat wkwkwkw tadinya mau sama praktek shalat jenazah alhamdulilah nya gajadi karna ppkm lg                    \n",
              "                                                                 ...                                                                                 \n",
              "95    wkwk ok melayu gak usah dibahas lagi wkwk walah sehat ya lu dan semoga orang rumah cepet sembuh alhamdulillah baik disini walau ppkm lev disini\n",
              "96    giliran puasa mau lebaran tiba ppkm                                                                                                            \n",
              "97    daerah di sumut menerapkan ppkm level mana saja                                                                                                \n",
              "98    kegiatan ppkm mikro di wilayah hukum polresoku                                                                                                 \n",
              "99    status ppkm di kota blitar naik ke level pada paken ini                                                                                        \n",
              "Name: Tweet_Text, Length: 100, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# translate to english before tokenize\n",
        "from itranslate import itranslate as itrans  \n",
        "\n",
        "tweetsa = []\n",
        "for index, row in tweets_df.iterrows():\n",
        "  tweetsa.append(itrans(row['Tweet_Text'],to_lang='en'))\n",
        "\n",
        "tweets_df['Tweet_Text_En']=tweetsa\n",
        "tweets_df['Tweet_Text_En']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WeNiLUuUBkT",
        "outputId": "6c5fdab8-d7f3-44bd-e468-e7dca890a304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     rt                                                                                                                                                                                 \n",
              "1     the stall closed again PPKM                                                                                                                                                        \n",
              "2     For the sake of the safety of the government, the government again implemented the PPKM to suppress the spread of the Covid variant of the Omicron Process of the Joint Brotherhood\n",
              "3     RT Sridianava Fill Chat Groups Mother Dizziness Gas Fuel Sembako Riding Dizziness Migor Soybean Tofu Tempe Rare Dizziness School Children Online                                   \n",
              "4     Memorizing Prayer and Dhikr After Prayers Wkwkwkw Want to Practice Prayers Thank God Alhamdulilah Karna Karna PPKM LG                                                              \n",
              "                                                              ...                                                                                                                        \n",
              "95    wkwk ok malay doesn't need to be discussed again wkwk he is healthy ya lu and may the house get well recovered Alhamdulillah good here though ppkm lev here                        \n",
              "96    the turn of fasting wants Lebaran arrives PPKM                                                                                                                                     \n",
              "97    the area in North Sumatra implements any level PPKM                                                                                                                                \n",
              "98    Micro PPKM activities in the legal region of Polresoku                                                                                                                             \n",
              "99    The status of PPKM in the city of Blitar rose to level on this pack                                                                                                                \n",
              "Name: Tweet_Text_En, Length: 100, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizing bahasa\n",
        "import string \n",
        "import re #regex library\n",
        "\n",
        "# import word_tokenize & FreqDist from NLTK\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "# ------ Tokenizing ---------\n",
        "\n",
        "# NLTK word rokenize \n",
        "def word_tokenize_wrapper(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "tweets_df['Tweet_Tokens'] = tweets_df['Tweet_Text'].apply(word_tokenize_wrapper)\n",
        "\n",
        "print('Tokenizing Result : \\n') \n",
        "print(tweets_df['Tweet_Tokens'].head())\n",
        "print('\\n\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8at_UzTmuqC",
        "outputId": "7d4069e1-eef2-4fd0-9f54-8df7ca9d1c80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing Result : \n",
            "\n",
            "0    [rt]                                                                                                                                                     \n",
            "1    [dah, tutup, warungnya, lagi, ppkm]                                                                                                                      \n",
            "2    [demi, keselamatan, masyarakat, pemerintah, kembali, terapkan, ppkm, untuk, menekan, penyebaran, covid, varian, omicron, prokes, ikhtiar, bersama]       \n",
            "3    [rt, sridianava, isi, chat, grup, para, emak, pusing, gas, bbm, sembako, naik, pusing, migor, kedelai, tahu, tempe, langka, pusing, anak, sekolah, onlin]\n",
            "4    [hafalan, doa, dan, dzikir, setelah, shalat, wkwkwkw, tadinya, mau, sama, praktek, shalat, jenazah, alhamdulilah, nya, gajadi, karna, ppkm, lg]          \n",
            "Name: Tweet_Tokens, dtype: object\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizing english, we call this dataset_en\n",
        "import string \n",
        "import re #regex library\n",
        "\n",
        "# import word_tokenize & FreqDist from NLTK\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "# ------ Tokenizing ---------\n",
        "\n",
        "# NLTK word rokenize \n",
        "def word_tokenize_wrapper(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "tweets_df['Tweet_Tokens_en'] = tweets_df['Tweet_Text_En'].apply(word_tokenize_wrapper)\n",
        "\n",
        "print('Tokenizing Result : \\n') \n",
        "print(tweets_df['Tweet_Tokens_en'].head())\n",
        "print('\\n\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3yZx2GOb5cC",
        "outputId": "8484f747-95f6-4677-f3e4-9ecd0affbcce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing Result : \n",
            "\n",
            "0    [rt]                                                                                                                                                                                                                 \n",
            "1    [the, stall, closed, again, PPKM]                                                                                                                                                                                    \n",
            "2    [For, the, sake, of, the, safety, of, the, government, ,, the, government, again, implemented, the, PPKM, to, suppress, the, spread, of, the, Covid, variant, of, the, Omicron, Process, of, the, Joint, Brotherhood]\n",
            "3    [RT, Sridianava, Fill, Chat, Groups, Mother, Dizziness, Gas, Fuel, Sembako, Riding, Dizziness, Migor, Soybean, Tofu, Tempe, Rare, Dizziness, School, Children, Online]                                               \n",
            "4    [Memorizing, Prayer, and, Dhikr, After, Prayers, Wkwkwkw, Want, to, Practice, Prayers, Thank, God, Alhamdulilah, Karna, Karna, PPKM, LG]                                                                             \n",
            "Name: Tweet_Tokens_en, dtype: object\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# translate to english after tokenize, we call this dataset_id_en\n",
        "\n",
        "tweetsa = []\n",
        "for index, row in tweets_df.iterrows():\n",
        "  tweetsa.append(itrans(row['Tweet_Tokens'],to_lang='en'))\n",
        "\n",
        "tweets_df['Tweet_Tokens_Id_En']=tweetsa\n",
        "tweets_df['Tweet_Tokens_Id_En']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW8jeZ6d8QNz",
        "outputId": "be67adf2-509a-4281-ec49-939d25a34387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     ['rt']                                                                                                                                                                                                                                 \n",
              "1     ['dah', 'closed', 'stall', 'again', 'ppkm']                                                                                                                                                                                            \n",
              "2     ['for the sake of', 'safety', 'community', 'government', 'back', 'Apply', 'PPKM', 'for', 'press',' spread ',' Covid ',' variant ',' Omicron ',' Prokes', 'Ikhtiar', 'Together']                                                        \n",
              "3     ['RT', 'Sridianava', 'Fill', 'Chat', 'Group', 'Para', 'Emak', 'Dizziness',' Gas', 'BBM', 'Sembako', 'Rise', ' dizziness', 'Migor', 'soybean', 'know', 'tempe', 'rare', 'dizziness',' child ',' school ',' online ']                    \n",
              "4     ['memorization', 'prayer', 'and', 'dhikr', 'after', 'prayer', 'wkwkwkw', 'before', 'want', 'same', 'practice', 'prayer', ' The body ',' thank God ',' he ',' Gajadi ',' Karna ',' PPKM ',' LG ']                                       \n",
              "                                                                                                    ...                                                                                                                                      \n",
              "95    ['wkwk', 'ok', 'Malay', 'no', 'need', 'discussed', 'again', 'wkwk', 'wake', 'healthy', 'yes',' Lu ',' And ',' hope ',' people ',' home ',' fast ',' recovered ',' Alhamdulillah ',' Good ',' HERE ',' DAY ',' PPKM ',' LEV ',' HERE ' ]\n",
              "96    ['turn', 'fasting', 'want', 'Lebaran', 'arrived', 'PPKM']                                                                                                                                                                              \n",
              "97    ['area', 'in', 'North Sumatra', 'implement', 'PPKM', 'Level', 'Mana', 'just']                                                                                                                                                          \n",
              "98    ['Activities', 'PPKM', 'Micro', 'in', 'Region', 'Law', 'Polresoku']                                                                                                                                                                    \n",
              "99    ['status', 'PPKM', 'on', 'City', 'Blitar', 'go up', 'to', 'level', 'on', 'Paken', 'this']                                                                                                                                              \n",
              "Name: Tweet_Tokens_Id_En, Length: 100, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK calc frequency distribution - dataset_id_en\n",
        "def freqDist_wrapper(text):\n",
        "    return FreqDist(text)\n",
        "\n",
        "tweets_df['Tweet_fdist_id_en'] = tweets_df['Tweet_Tokens_Id_En'].apply(freqDist_wrapper)\n",
        "\n",
        "print('Frequency Tokens : \\n') \n",
        "print(tweets_df['Tweet_fdist_id_en'].head().apply(lambda x : x.most_common()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFOkfw0Pcvql",
        "outputId": "6aa91bce-66a7-4c64-b29d-cd1f9647af47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequency Tokens : \n",
            "\n",
            "0    [(', 2), ([, 1), (r, 1), (t, 1), (], 1)]                                                                                                                                                                                                                                                                               \n",
            "1    [(', 10), (a, 4), (,, 4), ( , 4), (l, 3), (d, 2), (s, 2), (p, 2), ([, 1), (h, 1), (c, 1), (o, 1), (e, 1), (t, 1), (g, 1), (i, 1), (n, 1), (k, 1), (m, 1), (], 1)]                                                                                                                                                      \n",
            "2    [(', 32), ( , 22), (,, 15), (r, 10), (e, 10), (o, 9), (t, 7), (a, 7), (s, 6), (n, 5), (i, 5), (f, 4), (k, 4), (m, 4), (p, 4), (h, 3), (y, 3), (c, 3), (v, 3), (P, 3), (g, 2), (d, 2), ([, 1), (u, 1), (b, 1), (A, 1), (l, 1), (K, 1), (M, 1), (C, 1), (O, 1), (I, 1), (T, 1), (], 1)]                                  \n",
            "3    [(', 44), ( , 25), (,, 21), (i, 13), (a, 11), (e, 10), (s, 10), (n, 8), (o, 8), (r, 6), (z, 6), (l, 5), (d, 4), (h, 3), (m, 3), (k, 3), (R, 2), (S, 2), (t, 2), (G, 2), (p, 2), (B, 2), (M, 2), (b, 2), (c, 2), ([, 1), (T, 1), (v, 1), (F, 1), (C, 1), (u, 1), (P, 1), (E, 1), (D, 1), (g, 1), (y, 1), (w, 1), (], 1)]\n",
            "4    [(', 38), ( , 28), (,, 18), (a, 14), (r, 12), (e, 11), (o, 5), (i, 5), (t, 5), (n, 5), (d, 5), (k, 5), (w, 5), (p, 4), (y, 4), (h, 4), (m, 3), (G, 3), (f, 2), (b, 2), (c, 2), (K, 2), (P, 2), ([, 1), (z, 1), (s, 1), (T, 1), (j, 1), (M, 1), (L, 1), (], 1)]                                                         \n",
            "Name: Tweet_fdist_id_en, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK calc frequency distribution - dataset_en\n",
        "def freqDist_wrapper(text):\n",
        "    return FreqDist(text)\n",
        "\n",
        "tweets_df['Tweet_fdist_en'] = tweets_df['Tweet_Text_En'].apply(freqDist_wrapper)\n",
        "\n",
        "print('Frequency Tokens : \\n') \n",
        "print(tweets_df['Tweet_fdist_en'].head().apply(lambda x : x.most_common()))"
      ],
      "metadata": {
        "id": "7tOxHoDonqA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK Stopword bahasa, we call the rest dataset_id\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# ----------------------- get stopword from NLTK stopword -------------------------------\n",
        "# get stopword indonesia\n",
        "list_stopwords = stopwords.words('indonesian')\n",
        "\n",
        "# ---------------------------- manualy add stopword  ------------------------------------\n",
        "# append additional stopword\n",
        "list_stopwords.extend([\"yg\", \"dg\", \"rt\", \"dgn\", \"ny\", \"d\", 'klo', \n",
        "                       'kalo', 'amp', 'biar', 'bikin', 'bilang', \n",
        "                       'gak', 'ga', 'krn', 'nya', 'nih', 'sih', \n",
        "                       'si', 'tau', 'tdk', 'tuh', 'utk', 'ya', \n",
        "                       'jd', 'jgn', 'sdh', 'aja', 'n', 't', \n",
        "                       'nyg', 'hehe', 'pen', 'u', 'nan', 'loh', 'rt',\n",
        "                       '&amp', 'yah'])\n",
        "\n",
        "# ----------------------- add stopword from txt file ------------------------------------\n",
        "# read txt stopword using pandas\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "txt_stopword = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/csv/stopwords.txt', names= [\"stopwords\"], header = None)\n",
        "#df1 = df1[['id']]\n",
        "#df1\n",
        "\n",
        "#txt_stopword = pd.read_csv(\"stopwords.txt\", names= [\"stopwords\"], header = None)\n",
        "\n",
        "# convert stopword string to list & append additional stopword\n",
        "list_stopwords.extend(txt_stopword[\"stopwords\"][0].split(' '))\n",
        "\n",
        "# ---------------------------------------------------------------------------------------\n",
        "\n",
        "# convert list to dictionary\n",
        "list_stopwords = set(list_stopwords)\n",
        "\n",
        "#remove stopword pada list token\n",
        "def stopwords_removal(words):\n",
        "    return [word for word in words if word not in list_stopwords]\n",
        "\n",
        "tweets_df['Tweet_WSW_id'] = tweets_df['Tweet_Tokens'].apply(stopwords_removal) \n",
        "\n",
        "print(tweets_df['Tweet_WSW_id'].head())"
      ],
      "metadata": {
        "id": "UOOC4SVNoVAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normalization\n",
        "normalizad_word = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/csv/normalization.xlsx\")\n",
        "\n",
        "normalizad_word_dict = {}\n",
        "\n",
        "for index, row in normalizad_word.iterrows():\n",
        "    if row[0] not in normalizad_word_dict:\n",
        "        normalizad_word_dict[row[0]] = row[1] \n",
        "\n",
        "def normalized_term(document):\n",
        "    return [normalizad_word_dict[term] if term in normalizad_word_dict else term for term in document]\n",
        "\n",
        "tweets_df['tweet_normalized_id'] = tweets_df['Tweet_WSW_id'].apply(normalized_term)\n",
        "\n",
        "tweets_df['tweet_normalized_id'].head(10)"
      ],
      "metadata": {
        "id": "XsTb_yBDtox8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEMMING for bahasa\n",
        "# import Sastrawi package\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "import swifter\n",
        "\n",
        "# create stemmer\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "# stemmed\n",
        "def stemmed_wrapper(term):\n",
        "    return stemmer.stem(term)\n",
        "\n",
        "term_dict = {}\n",
        "\n",
        "for document in tweets_df['tweet_normalized_id']:\n",
        "    for term in document:\n",
        "        if term not in term_dict:\n",
        "            term_dict[term] = ' '\n",
        "            \n",
        "print(len(term_dict))\n",
        "print(\"------------------------\")\n",
        "\n",
        "for term in term_dict:\n",
        "    term_dict[term] = stemmed_wrapper(term)\n",
        "    print(term,\":\" ,term_dict[term])\n",
        "    \n",
        "print(term_dict)\n",
        "print(\"------------------------\")\n",
        "\n",
        "\n",
        "# apply stemmed term to dataframe\n",
        "def get_stemmed_term(document):\n",
        "    return [term_dict[term] for term in document]\n",
        "\n",
        "tweets_df['tweet_stemmed_id'] = tweets_df['tweet_normalized_id'].swifter.apply(get_stemmed_term)\n",
        "print(tweets_df['tweet_stemmed_id'])"
      ],
      "metadata": {
        "id": "S5AAAw10tXzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# translate to english after formalized\n",
        "\n",
        "tweetsa = []\n",
        "for index, row in tweets_df.iterrows():\n",
        "  tweetsa.append(itrans(row['tweet_stemmed_id'],to_lang='en'))\n",
        "\n",
        "tweets_df['tweet_id']=tweetsa\n",
        "tweets_df['tweet_id']"
      ],
      "metadata": {
        "id": "ALz1WGpu9Nrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download preprocessed dataset_id\n",
        "# file_name = '/content/drive/MyDrive/Colab Notebooks/csv/dataset_id_preprocess_PPKM.csv'\n",
        "file_name = 'dataset_id_preprocess_PPKM.csv'\n",
        "tweets_df.to_csv(file_name, encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "SUlJ3DQu3E4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download preprocessed dataset_id_en\n",
        "# file_name = '/content/drive/MyDrive/Colab Notebooks/csv/dataset_id_en_preprocess_PPKM.csv'\n",
        "file_name = 'dataset_id_en_preprocess_PPKM.csv'\n",
        "tweets_df.to_csv(file_name, encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "ZeiJ7mNoe3WR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download preprocessed dataset_en\n",
        "# file_name = '/content/drive/MyDrive/Colab Notebooks/csv/dataset_en_preprocess_PPKM.csv'\n",
        "file_name = 'dataset_en_preprocess_PPKM.csv'\n",
        "tweets_df.to_csv(file_name, encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "GWu703L5e5FJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#textblob on dataset_id\n"
      ],
      "metadata": {
        "id": "2JUB0bxTjj1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#textblob on dataset_id_en\n",
        "from textblob import TextBlob\n",
        "\n",
        "for index, row in tweets_df.iterrows():\n",
        "  tweetsa.append(itrans(row['Tweet_Token_Id_en'],to_lang='en'))\n",
        "\n",
        "tweets_df['Tweet_Token_En']=tweetsa\n",
        "tweets_df['Tweet_Token_En']"
      ],
      "metadata": {
        "id": "ZEsSUnQTjjDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#textblob on dataset_en\n",
        "# def getSubjectivity(text):\n",
        "#    return TextBlob(text).sentiment.subjectivity\n",
        "\n",
        "#Create a function to get the polarity\n",
        "# def getPolarity(text):\n",
        "#    return TextBlob(text).sentiment.polarity\n",
        "\n",
        "def getAnalysis(score):\n",
        "  if score < 0:\n",
        "    return 'Negative'\n",
        "  elif score == 0:\n",
        "    return 'Neutral'\n",
        "  else:\n",
        "    return 'Positive'\n",
        " \n",
        "for index, row in tweets_df.iterrows():\n",
        "  tweets_df['TextBlob_Subjectivity'] = TextBlob(row['Tweet_Text_En']).sentiment.subjectivity\n",
        "  tweets_df['TextBlob_Polarity'] = TextBlob(row['Tweet_Text_En']).sentiment.polarity\n",
        "  if TextBlob(row['Tweet_Text_En']).sentiment.polarity < 0:\n",
        "    score = 'Negative'\n",
        "  elif TextBlob(row['Tweet_Text_En']).sentiment.polarity == 0:\n",
        "    score = 'Neutral'\n",
        "  else:\n",
        "    score = 'Positive'\n",
        "  tweets_df['TextBlob_Analysis'] = score\n",
        "\n",
        "#df to csv on result\n",
        "# file_name = '/content/drive/MyDrive/Colab Notebooks/csv/dataset_en_analysis_PPKM.csv'\n",
        "file_name = 'dataset_en_analysis_PPKM.csv'\n",
        "tweets_df.to_csv(file_name, encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "fh_FIhp0jV9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vader on dataset_en\n",
        "# from vaderSentiment.vaderSentiment module.\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# function to print sentiments\n",
        "# of the sentence.\n",
        "def sentiment_scores(sentence):\n",
        "\n",
        "\t# Create a SentimentIntensityAnalyzer object.\n",
        "\tsid_obj = SentimentIntensityAnalyzer()\n",
        "\n",
        "\t# polarity_scores method of SentimentIntensityAnalyzer\n",
        "\t# object gives a sentiment dictionary.\n",
        "\t# which contains pos, neg, neu, and compound scores.\n",
        "\tsentiment_dict = sid_obj.polarity_scores(sentence)\n",
        "\t\n",
        "\t# decide sentiment as positive, negative and neutral\n",
        "\tif sentiment_dict['compound'] >= 0.05 :\n",
        "\t\tscore = 'Positive'\n",
        "\telif sentiment_dict['compound'] <= - 0.05 :\n",
        "\t\tscore = 'Negative'\n",
        "\telse :\n",
        "\t\tscore = 'Neutral'\n",
        "  tweets_df['Vader_Analysis'] = score\n",
        "  tweets_df['Vader_pos_rate'] = sentiment_dict['pos']\n",
        "  tweets_df['Vader_neu_rate'] = sentiment_dict['neu']\n",
        "  tweets_df['Vader_neg_rate'] = sentiment_dict['neg']\n",
        " \n",
        "for index, row in tweets_df.iterrows():\n",
        "  sentiment_scores(row['Tweet_Text_En'])\n",
        "\n"
      ],
      "metadata": {
        "id": "jiVNYkpUx2E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
        "\n"
      ],
      "metadata": {
        "id": "mmom52jQw2XX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
        "\n"
      ],
      "metadata": {
        "id": "ntkzDW2Ew_cv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
        "\n"
      ],
      "metadata": {
        "id": "0BlJ_HjBw_Kd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
        "\n"
      ],
      "metadata": {
        "id": "WLXLHIbmw-x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentiment Analysis\n",
        "def percentage(part,whole):\n",
        " return 100 * float(part)/float(whole)\n",
        "keyword = 'lockdown'\n",
        "noOfTweet = 100\n",
        "tweets= tweepy.Paginator(client.search_recent_tweets, query=keyword,\n",
        "                              tweet_fields=['context_annotations', 'created_at']).flatten(limit=noOfTweet)\n",
        "positive = 0\n",
        "negative = 0\n",
        "neutral = 0\n",
        "polarity = 0\n",
        "tweet_list = []\n",
        "neutral_list = []\n",
        "negative_list = []\n",
        "positive_list = []\n",
        "for tweet in tweets:\n",
        "  #print(tweet.text)\n",
        "  tweet_list.append(tweet.text)\n",
        "  analysis = TextBlob(tweet.text)\n",
        "  score = SentimentIntensityAnalyzer().polarity_scores(tweet.text)\n",
        "  neg = score['neg']\n",
        "  neu = score['neu']\n",
        "  pos = score['pos']\n",
        "  comp = score['compound']\n",
        "  polarity += analysis.sentiment.polarity\n",
        "\n",
        "  if neg > pos:\n",
        "    negative_list.append(tweet.text)\n",
        "    negative += 1\n",
        "  elif pos > neg:\n",
        "    positive_list.append(tweet.text)\n",
        "    positive += 1\n",
        "  elif pos == neg:\n",
        "    neutral_list.append(tweet.text)\n",
        "    neutral += 1\n",
        "\n",
        "positive = percentage(positive, noOfTweet)\n",
        "negative = percentage(negative, noOfTweet)\n",
        "neutral = percentage(neutral, noOfTweet)\n",
        "polarity = percentage(polarity, noOfTweet)\n",
        "positive = format(positive, '.1f')\n",
        "negative = format(negative, '.1f')\n",
        "neutral = format(neutral, '.1f')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "gF4v_93aRpJv",
        "outputId": "a9070431-f8de-424c-c5f9-61a20a75071c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TooManyRequests",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTooManyRequests\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-7ac16c22eb19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mnegative_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mpositive_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0;31m#print(tweet.text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mtweet_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tweepy/pagination.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(self, limit)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         for response in PaginationIterator(self.method, *self.args,\n\u001b[0;32m---> 49\u001b[0;31m                                            **self.kwargs):\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tweepy/pagination.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pagination_token\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpagination_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevious_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"previous_token\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tweepy/client.py\u001b[0m in \u001b[0;36msearch_recent_tweets\u001b[0;34m(self, query, user_auth, **params)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0;34m\"since_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sort_order\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"start_time\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tweet.fields\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 \u001b[0;34m\"until_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"user.fields\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             ), data_type=Tweet, user_auth=user_auth\n\u001b[0m\u001b[1;32m    921\u001b[0m         )\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tweepy/client.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, method, route, params, endpoint_parameters, json, data_type, user_auth)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         response = self.request(method, route, params=request_params,\n\u001b[0;32m--> 119\u001b[0;31m                                 json=json, user_auth=user_auth)\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tweepy/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, route, params, json, user_auth)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_auth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTooManyRequests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTwitterServerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTooManyRequests\u001b[0m: 429 Too Many Requests"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Number of Tweets (Total, Positive, Negative, Neutral)\n",
        "tweet_list = pd.DataFrame(tweet_list)\n",
        "neutral_list = pd.DataFrame(neutral_list)\n",
        "negative_list = pd.DataFrame(negative_list)\n",
        "positive_list = pd.DataFrame(positive_list)\n",
        "print(\"total number: \",len(tweet_list))\n",
        "print(\"positive number: \",len(positive_list))\n",
        "print(\"negative number: \", len(negative_list))\n",
        "print(\"neutral number: \",len(neutral_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvL1pjWvUhhV",
        "outputId": "adb5deb4-e8d1-4de9-994c-e87c5b9059dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total number:  0\n",
            "positive number:  0\n",
            "negative number:  1\n",
            "neutral number:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating PieCart\n",
        "labels = ['Positive ['+str(positive)+'%]' , 'Neutral ['+str(neutral)+'%]','Negative ['+str(negative)+'%]']\n",
        "sizes = [positive, neutral, negative]\n",
        "colors = ['yellowgreen', 'blue','red']\n",
        "patches, texts = plt.pie(sizes,colors=colors, startangle=90)\n",
        "plt.style.use('default')\n",
        "plt.legend(labels)\n",
        "plt.title(\"Sentiment Analysis Result for keyword= \"+keyword+\"\" )\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "adnBAeMvVB0K",
        "outputId": "9096b18c-844d-4900-d9a4-8406109e5043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = 'tweet_scraped_data.csv'\n",
        "tweets_df.to_csv(file_name, encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "qQCL5Rs7VRLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = pd.read_csv(\"https://raw.githubusercontent.com/kolaveridi/kaggle-Twitter-US-Airline-Sentiment-/master/Tweets.csv\")\n",
        "file_name = 'tweet_scraped_data.csv'\n",
        "tweets.to_csv(file_name, encoding='utf-8', index=False)\n"
      ],
      "metadata": {
        "id": "EzdMUfNYZBhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9oXe-FD5Mhk"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95UH_T4B5Mhm"
      },
      "source": [
        "[1] http://docs.tweepy.org/en/latest/api.html#status-methods\n",
        "[2] https://www.earthdatascience.org/courses/use-data-open-source-python/intro-to-apis/twitter-data-in-python/\n",
        "[3] https://towardsdatascience.com/how-to-scrape-tweets-from-twitter-59287e20f0f1\n",
        "[4] https://dev.to/twitterdev/a-comprehensive-guide-for-using-the-twitter-api-v2-using-tweepy-in-python-15d9"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:nlp]",
      "language": "python",
      "name": "conda-env-nlp-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}